{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddab464c",
   "metadata": {},
   "source": [
    "Here’s a step-by-step guide to help you start approach your first Data Science project:\n",
    "\n",
    "Start with Your Research Goal\n",
    "Before writing any code, take a moment to frame your project around a research or business question.\n",
    "\n",
    "- Step 1: Choose a dataset you're interested in.\n",
    "\n",
    "- Step 2: Define one or two open-ended questions.\n",
    "These should be exploratory, not yes/no questions. \n",
    "\n",
    "Ask yourself:\n",
    " - What do I want to learn, prove, or explore with this data?\n",
    "\n",
    "Examples of open-ended research questions. Use flexible templates like these:\n",
    "\n",
    " - What is the impact of [X] on [Y]?\n",
    " - [X] will usually be a category or group\n",
    " - [Y] is an outcome you want to understand or explain\n",
    "it can be represented by one or more columns in your dataset, or it might involve creating a new one\n",
    "What trends or patterns can I find in [key behavior or metric]?\n",
    "\n",
    "This general question will help you decide:\n",
    " - which columns matter?\n",
    " - what to clean?\n",
    " - what patterns to look for?\n",
    " - what types of plots or groupings to use?\n",
    "\n",
    "Your research questions should guide every step of your analysis: from cleaning to EDA to the final SQL queries.\n",
    "\n",
    "###<h1 Data Cleaning h1#>\n",
    "\n",
    "Once you’ve selected your dataset, begin by exploring and cleaning the data. The goal is to prepare a clean, focused dataset that aligns with your research questions. Start by loading your dataset using pandas. Then:\n",
    "Use .head(), .shape and .info() to get a feel for the data structure.\n",
    "\n",
    "Check for:\n",
    "\n",
    "Missing values - identify where your data might be incomplete (df.isnull().sum())\n",
    "\n",
    "Duplicates (full rows) - avoid repeated data entries (df.duplicated().sum())\n",
    "\n",
    "Duplicates in key columns - check for duplicates in fields that should be unique (e.g., user ID, transaction ID)\n",
    "\n",
    "Data types - make sure columns are correctly typed (df.dtypes)\n",
    "\n",
    "Number of unique values per column (df.nunique()) - helps identify which columns are likely categorical\n",
    "If a column has only a handful of unique values compared to the number of rows, it likely represents a category, not a continuous variable.\n",
    "Invalid or extreme values (e.g., negative ages or impossible prices) - these can often be spotted in the output of: df.describe(include=\"all\")\n",
    "\n",
    "Start cleaning:\n",
    "Drop unnecessary columns\n",
    "Keep only the variables that help you answer your research questions.\n",
    "If a column like an ID is unique and not used in your analysis, consider setting it as the index (e.g., df.set_index(\"user_id\")) instead of dropping it.\n",
    "\n",
    "Handle missing values:\n",
    "Decide on a strategy based on the column’s importance and the amount of missing data:\n",
    "Drop rows or columns (df.dropna())\n",
    "Fill in values with mean, median, mode, or a placeholder (df.fillna())\n",
    "Or keep them (if missingness itself tells you something!)\n",
    "\n",
    "Handle duplicates:\n",
    "Remove fully duplicated rows with df.drop_duplicates()\n",
    "\n",
    "Convert column types where needed:\n",
    "Use [pd.to](http://pd.to/)``_datetime() for date fields\n",
    "Use .astype() to fix numeric or categorical types\n",
    "\n",
    "Fix or remove invalid values:\n",
    "Decide whether to correct, remove, or flag them based on your analysis goals\n",
    "\n",
    "DON'T FORGET TO:\n",
    "Document your cleaning process\n",
    "Write explanations in Markdown cells as you go\n",
    "This makes your notebook readable and explains your decision-making clearly.\n",
    "\n",
    "AND FINALLY:\n",
    "Save your cleaned dataset as a new CSV file:\n",
    "[df.to](http://df.to/)``_csv(\"cleaned_data.csv\", index=False)\n",
    "(You will be using this cleaned dataset in SQL later on)\n",
    "\n",
    "[EDA]\n",
    "You are now done with Data Cleaning and ready to proceed to EDA!\n",
    "Follow your Univariate and Bivariate lesson notebooks to guide your process.\n",
    "\n",
    "Step 1: Identify Variable Types\n",
    "Classify your columns into:\n",
    "Numerical variables (e.g., age, income)\n",
    "Categorical variables (e.g., gender, country)\n",
    "This classification determines what types of plots and summary statistics you’ll use.\n",
    "\n",
    "Step 2: Univariate EDA (One Variable at a Time)\n",
    "Now, explore each variable individually - but only the ones relevant to your goal.\n",
    "For numerical variables:\n",
    "Use .describe() for summary stats.\n",
    "Visualize distributions with histograms or boxplots.\n",
    "For categorical variables:\n",
    "Use .value_counts() to see frequency counts.\n",
    "Visualize with bar plots (or pie charts, if you must :smile:).\n",
    "This step helps you understand the shape, spread, and patterns in your key variables.\n",
    "\n",
    "Step 3: Bivariate EDA (Two Variables at a Time)\n",
    "After univariate EDA, analyze relationships between two or more variables using:\n",
    "Grouped summaries (e.g., df.groupby())\n",
    "Cross-tabs (e.g., pd.crosstab())\n",
    "Scatter plots, bar plots, boxplots, etc.\n",
    "Again, focus only on the relationships that are relevant to your research question.\n",
    "\n",
    "Step 4: From EDA to SQL Questions\n",
    "Once you understand your data:\n",
    "Develop at least 10 simple questions that your cleaned dataset could help answer.\n",
    "These questions should be:\n",
    "Relevant to your research goal\n",
    "Based on insights from your EDA\n",
    "Answerable using simple SQL queries\n",
    "Example questions:\n",
    "What is the average age of customers in each region?\n",
    "How many products were purchased by each membership type?\n",
    "What is the total revenue per product category?\n",
    "\n",
    "As you continue to work on your first Data Science project, remember that the goal is to build an MVP (Minimum Viable Product/ Project): a small, clear, and complete first version of your analysis.Here’s what that means in practice:You can clearly state your research questionYou have a clean dataset that supports that questionYou’ve explored 1–2 numerical and 1–2 categorical variablesYou’ve made at least 3-4 univariate plots and two bivariate plotsYou’ve developed 10 follow-up questions that can be answered using SQL, and written the queries and answers for themThat’s all you need for a strong first submission, no need to analyze everything!Start small, focus on clarity, and build from there. What to Submit (by Friday):Your Jupyter Notebook (.ipynb), with all your cleaning, EDA, and explanationsYour SQL file: the queries you’ll run later on the cleaned datasetYour Presentation slides with the presentation you will do on Friday morning (10 min per group).We’ll show you how to create your own GitHub repository and upload everything on Friday, so for now just make sure your files are ready and organized in a local Project folder"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
